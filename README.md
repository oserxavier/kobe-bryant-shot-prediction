# kobe-bryant-shot-prediction
Projeto final da disciplina Engenharia de Machine Learning - INFNET. Neste reposit√≥rio desenvolvemos um modelo preditivo para arremessos de Kobe Bryant utilizando t√©cnicas de classifica√ß√£o, MLOps com MLflow, PyCaret e Streamlit, seguindo o framework TDSP da Microsoft.


Modelo preditivo para acertos de arremessos do Kobe Bryant com MLflow, PyCaret e Streamlit. Projeto final - Engenharia de ML | INFNET.
# Projeto Kobe Bryant Shot Prediction

## üìå Descri√ß√£o Geral

Este reposit√≥rio cont√©m o desenvolvimento do projeto final da disciplina **Engenharia de Machine Learning** do Instituto INFNET. O objetivo principal √© aplicar conceitos de MLOps, AutoML, visualiza√ß√£o de dados e estrutura√ß√£o de pipelines utilizando o framework **TDSP (Team Data Science Process)** da Microsoft.

## Objetivo

Prever se Kobe Bryant acertou ou errou um arremesso durante sua carreira na NBA com base em dados hist√≥ricos, utilizando abordagens de **classifica√ß√£o e regress√£o** com bibliotecas como **PyCaret**, **Scikit-learn**, **MLflow** e **Streamlit**.

## Dados

Os dados utilizados neste projeto foram fornecidos pela disciplina e est√£o dispon√≠veis neste link:  
[https://www.kaggle.com/c/kobe-bryant-shot-selection/data](https://www.kaggle.com/c/kobe-bryant-shot-selection/data)

Os arquivos devem ser salvos na seguinte estrutura dentro do reposit√≥rio:

/data/raw/dataset_kobe_dev.parquet
/data/raw/dataset_kobe_prod.parquet


## Instru√ß√µes Iniciais de Uso

1. Clone este reposit√≥rio:
   ```bash
   git clone https://github.com/seu-usuario/kobe-bryant-shot-prediction.git
   cd kobe-bryant-shot-prediction

python -m venv venv
source venv/bin/activate  # ou venv\Scripts\activate no Windows

pip install -r requirements.txt

## Diagrama do Pipeline de Machine Learning

Abaixo est√° o fluxo completo do projeto:

![Diagrama do pipeline](docs/diagrama_pipeline.png)

## Papel das Ferramentas no Pipeline de Machine Learning

### 1. Rastreamento de Experimentos
- **MLflow** √© essencial para acompanhar o hist√≥rico de execu√ß√µes, registrando par√¢metros, m√©tricas, modelos e artefatos. Ele permite comparar experimentos e manter rastreabilidade.
- **PyCaret**, integrado com MLflow, registra automaticamente cada execu√ß√£o de modelo e seus resultados com m√≠nimo esfor√ßo de configura√ß√£o.

### 2. Fun√ß√µes de Treinamento
- **Scikit-learn** fornece os algoritmos principais utilizados no projeto, como Regress√£o Log√≠stica e √Årvore de Decis√£o.
- **PyCaret** automatiza grande parte do pipeline de modelagem: limpeza, sele√ß√£o de atributos, valida√ß√£o cruzada, tuning de hiperpar√¢metros e compara√ß√£o entre modelos.

### 3. Monitoramento da Sa√∫de do Modelo
- **MLflow** permite registrar m√©tricas como `log loss` e `f1_score`, que ajudam a acompanhar a performance do modelo ao longo do tempo.
- A partir dessas m√©tricas, √© poss√≠vel identificar degrada√ß√£o do modelo e tomar a√ß√µes corretivas.
- Em conjunto com **Streamlit**, √© poss√≠vel construir dashboards para visualiza√ß√£o em tempo real dessas m√©tricas.

### 4. Atualiza√ß√£o do Modelo
- Atrav√©s de pipelines versionados e reus√°veis, **MLflow** permite a atualiza√ß√£o cont√≠nua dos modelos com novos dados.
- **PyCaret** facilita o re-treinamento do modelo com os mesmos passos aplicados anteriormente, garantindo consist√™ncia.
  
### 5. Provisionamento (Deployment)
- **MLflow** disponibiliza APIs REST com o comando `mlflow models serve`, facilitando a publica√ß√£o dos modelos em ambientes locais ou em nuvem.
- **Streamlit** permite desenvolver interfaces simples e eficientes para testar o modelo em tempo real, com inputs de usu√°rios e visualiza√ß√£o dos resultados.

---

##  Artefatos do Projeto

Durante o desenvolvimento deste projeto, os seguintes artefatos ser√£o criados e armazenados conforme a estrutura TDSP:

###  `/data/raw/`
- **dataset_kobe_dev.parquet**  
  Conjunto de dados com as informa√ß√µes hist√≥ricas de arremessos de Kobe Bryant, usado para desenvolvimento e treinamento do modelo.

- **dataset_kobe_prod.parquet**  
  Conjunto de dados simulado para produ√ß√£o, usado para aplicar o modelo final treinado.

---

### `/data/processed/`
- **data_filtered.parquet**  
  Base resultante ap√≥s tratamento de dados: sele√ß√£o de colunas relevantes e remo√ß√£o de valores ausentes.

- **base_train.parquet**  
  Subconjunto com 80% dos dados, estratificado, usado para treinamento do modelo.

- **base_test.parquet**  
  Subconjunto com 20% dos dados, estratificado, usado para valida√ß√£o do modelo.

- **resultados_aplicacao.parquet**  
  Resultados das previs√µes do modelo aplicadas sobre a base de produ√ß√£o, contendo as m√©tricas de avalia√ß√£o.

---

### `/code/`
- **data_prep/preparacao_dados.py**  
  Script respons√°vel por realizar o tratamento dos dados brutos, gerar os arquivos processados e registrar essa etapa no MLflow com a run ‚ÄúPreparacaoDados‚Äù.

- **training/treinamento_modelos.py**  
  Script que realiza o treinamento dos modelos (Regress√£o Log√≠stica e √Årvore de Decis√£o) com PyCaret, registra as m√©tricas e salva o melhor modelo.

- **inference/aplicacao.py**  
  Script que carrega a base de produ√ß√£o, aplica o modelo salvo e registra a execu√ß√£o com a run ‚ÄúPipelineAplicacao‚Äù no MLflow.

---

### `/outputs/`
- **mlruns/**  
  Diret√≥rio gerado pelo MLflow com todos os logs de execu√ß√µes, m√©tricas, par√¢metros e modelos treinados.

---

### `/docs/`
- **diagrama_pipeline.png**  
  Representa√ß√£o gr√°fica do fluxo de trabalho do projeto, desde a coleta de dados at√© a operacionaliza√ß√£o do modelo.

---

### Arquivos adicionais
- **requirements.txt**  
  Lista com todas as depend√™ncias necess√°rias para rodar o projeto.

- **README.md**  
  Documenta√ß√£o completa do projeto, contendo descri√ß√£o, objetivos, instru√ß√µes de uso, artefatos e respostas conceituais.

---
1. Qual a dimens√£o resultante do dataset ap√≥s limpeza?
Dimens√£o final do dataset: (20285, 7)
S√£o 20.285 registros v√°lidos com 7 colunas
---
2. Como a escolha de treino/teste afeta o modelo?
A escolha impacta diretamente na generaliza√ß√£o do modelo. Usar uma divis√£o aleat√≥ria e estratificada garante representatividade das classes, evita vi√©s e melhora a avalia√ß√£o real do desempenho.
---
3. Estrat√©gias para minimizar vi√©s de dados?
- Divis√£o estratificada
- Valida√ß√£o cruzada (k-fold)
- Acompanhamento cont√≠nuo da performance em produ√ß√£o
- Balanceamento de classes (se necess√°rio)